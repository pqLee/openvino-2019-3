models:
  - name: NCF_example

    # list of launchers for your topology.
    launchers:
        # launcher framework (e.g. caffe, dlsdk)
      - framework: dlsdk
        # device for infer (e.g. for dlsdk cpu, gpu, hetero:cpu, gpu ...)
        device: CPU
        cpu_extensions: libcpu_extension.so
        # topology IR (*.prototxt for caffe, *.xml for InferenceEngine, etc)
        # path to topology is prefixed with directory, specified in "-m/--models" option
        model:   graph_frozen.xml
        # topology weights binary (*.caffemodel for caffe, *.bin for InferenceEngine)
        weights: graph_frozen.bin
        # launcher returns raw result, so it should be converted
        # to an appropriate representation with adapter
        adapter: hit_ratio_adapter

        inputs:
            - type: INPUT
              value: "u"
              name: embedding/embedding_lookup/placeholder_port_1
            - type: INPUT
              value: "i"
              name: embedding_1/embedding_lookup/placeholder_port_1
            - type: INPUT
              value: "u"
              name: embedding_2/embedding_lookup/placeholder_port_1
            - type: INPUT
              value: "i"
              name: embedding_3/embedding_lookup/placeholder_port_1

    # metrics, preprocessing and postprocessing are typically dataset specific, so dataset field
    # specifies data and all other steps required to validate topology
    # there is typically definitions file, which contains options for common datasets and which is merged
    # during evaluation, but since "sample_dataset" is not used anywhere else, this config contains full definition
    datasets:
      # uniquely distinguishable name for dataset
      # note that all other steps are specific for this dataset only
      # if you need to test topology on multiple datasets, you need to specify
      # every step explicitly for each dataset
      - name: ncf_validation_dataset.npy
        # directory where input images are searched.
        # prefixed with directory specified in "-s/--source" option
        # name of converted annotation file (specified in -a option during annotation conversion)
        # prefixed with directory specified in "-a/--annotations" option
        annotation: ncf_converter.pickle
        dataset_meta: ncf_converter.json

        reader: ncf_data_reader

        # list of metrics, calculated on dataset
        metrics:
          - type: hit_ratio
          - type: ndcg
